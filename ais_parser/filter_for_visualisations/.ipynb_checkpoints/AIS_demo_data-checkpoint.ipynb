{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIS-PARSER DATA PLOTING\n",
    "\n",
    "Dans cette démo, nous examinerons un fichier csv prétraité contenant des transitions id-état-action-état pour tracer les trajectoires discrétisées correspondantes des navires sur une carte. Pour plus d'informations sur la façon dont ce csv a été généré, veuillez vous référer à `` README.md '' ou `` processplotter.py ''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous chargeons les métadonnées. Les métadonnées spécifient les dimensions et la résolution de la grille en longitude et latitude (et plus) afin que nous puissions tracer les trajectoires discrétisées sur une carte en mappant les coordonnées sur les états. Le `` grid_params ['grid_len'] `` est la longueur de côté d'un carré en degrés d'une grille euclidienne régulière avec des colonnes `` grid_params ['num_cols'] ``. Avec ces informations, nous pouvons déduire les limites d'un carré de grille à partir d'un état entier. Les métadonnées contiennent également une copie de la façon dont le prétraitement a été effectué afin que nous puissions connaître le format du csv. Le csv aura 2 colonnes supplémentaires de longitude et de latitude si `` options ['append_coords'] `` est vrai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_files_meta': {'AIS_2020_01_02.csv': {'day': 2, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_03.csv': {'day': 3, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_04.csv': {'day': 4, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_05.csv': {'day': 5, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_06.csv': {'day': 6, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_07.csv': {'day': 7, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_08.csv': {'day': 8, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_09.csv': {'day': 9, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_10.csv': {'day': 10, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_11.csv': {'day': 11, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_12.csv': {'day': 12, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_13.csv': {'day': 13, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_14.csv': {'day': 14, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_15.csv': {'day': 15, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_16.csv': {'day': 16, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_17.csv': {'day': 17, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_18.csv': {'day': 18, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_19.csv': {'day': 19, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_20.csv': {'day': 20, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_21.csv': {'day': 21, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_22.csv': {'day': 22, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_23.csv': {'day': 23, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_24.csv': {'day': 24, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_25.csv': {'day': 25, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_26.csv': {'day': 26, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_27.csv': {'day': 27, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_28.csv': {'day': 28, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_29.csv': {'day': 29, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_30.csv': {'day': 30, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_31.csv': {'day': 31, 'month': 1, 'year': 2020}},\n",
       " 'directories': {'in_dir_data': 'ais_data_output.csv',\n",
       "  'in_dir_path': '../filtered_data_for_visualization/'},\n",
       " 'grid_params': {'grid_len': 0.5,\n",
       "  'max_lat': 50.0,\n",
       "  'max_lon': -61.0,\n",
       "  'min_lat': 25.0,\n",
       "  'min_lon': -141.0,\n",
       "  'num_cols': 160},\n",
       " 'options': {'allow_diag': False,\n",
       "  'append_coords': True,\n",
       "  'bound_lat': True,\n",
       "  'bound_lon': False,\n",
       "  'bound_time': True,\n",
       "  'interp_actions': True,\n",
       "  'limit_rows': True,\n",
       "  'max_rows': 100000,\n",
       "  'min_states': 2,\n",
       "  'prec_coords': 3}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_file= 'meta_data.yml'\n",
    "ais_meta = {}\n",
    "with open(meta_file, 'r') as stream:\n",
    "    try:\n",
    "        ais_meta = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "all_files_meta = ais_meta['all_files_meta']\n",
    "options = ais_meta['options']\n",
    "directories = ais_meta['directories']\n",
    "grid_params = ais_meta['grid_params']\n",
    "\n",
    "# spécifie le répertoire d'entrée et les fichiers d'intérêt\n",
    "in_dir_path = directories['in_dir_path']\n",
    "in_dir_data = directories['in_dir_data']\n",
    "\n",
    "ais_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous chargeons les séquences.\n",
    "\n",
    "Dans cet ensemble de données, il pourrait y avoir des milliers de trajectoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../filtered_data_for_visualization/ais_data_output.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-89b5b96b93e0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# reads in first file of interest\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mais_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0min_dir_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0min_dir_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mais_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    603\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 605\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    607\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 457\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    458\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    459\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    812\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    813\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 814\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    815\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    816\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1043\u001B[0m             )\n\u001B[1;32m   1044\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1045\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1046\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1047\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   1860\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1861\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1862\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1863\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1864\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\"storage_options\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"encoding\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"memory_map\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"compression\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m   1355\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHanldes\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1356\u001B[0m         \"\"\"\n\u001B[0;32m-> 1357\u001B[0;31m         self.handles = get_handle(\n\u001B[0m\u001B[1;32m   1358\u001B[0m             \u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1359\u001B[0m             \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    640\u001B[0m                 \u001B[0merrors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"replace\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    641\u001B[0m             \u001B[0;31m# Encoding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 642\u001B[0;31m             handle = open(\n\u001B[0m\u001B[1;32m    643\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    644\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../filtered_data_for_visualization/ais_data_output.csv'"
     ]
    }
   ],
   "source": [
    "# lit dans le premier fichier d'intérêt\n",
    "ais_data = pd.read_csv(in_dir_path + in_dir_data)\n",
    "\n",
    "ais_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons une fonction qui convertit les `` state_id``s de `` ais_data`` en coordonnées correspondant au milieu de ce carré de la grille pour le traçage si `` options ['append_coords'] `` n'était pas défini sur `` True '' avant le prétraitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_coord(state):\n",
    "    state_col = state % grid_params['num_cols']\n",
    "    state_row = state // grid_params['num_cols']\n",
    "    state_lon = grid_params['min_lon'] + grid_params['grid_len'] * (state_col + 0.5)\n",
    "    state_lat = grid_params['min_lat'] + grid_params['grid_len'] * (state_row + 0.5)\n",
    "    return state_lon, state_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons des pandas pour ajouter des colonnes de coordonnées à notre dataframe qui contiendront les coordonnées du centre de chaque état dans chaque séquence, si cela n'a pas été fait dans le prétraitement en définissant `` options ['append_coords'] `` sur `` True` »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not options['append_coords']:\n",
    "    ais_data[['lon', 'lat']] = ais_data.apply(lambda x: state_to_coord(x['from_state_id']), axis=1, result_type='expand')\n",
    "ais_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec les latitudes et longitudes maintenant disponibles, nous ajoutons une dernière ligne à chaque trajectoire avec juste le dernier état afin qu'une cartographie un à un de l'état aux coordonnées soit formée, si cela n'a pas déjà été fait lors du prétraitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not options['append_coords']:\n",
    "    sequence_dfs = pd.DataFrame(columns=['sequence_id', 'from_state_id', 'action_id', 'to_state_id', 'lon', 'lat'])\n",
    "    for traj_num, traj in ais_data.groupby('sequence_id'):\n",
    "        # ajoute la dernière ligne fictive à chaque séquence avec juste l'état final de la trajectoire\n",
    "        last_state = traj['to_state_id'].iloc[-1]\n",
    "        last_lon, last_lat = state_to_coord(last_state)\n",
    "\n",
    "        final_state = {'sequence_id': traj_num, 'from_state_id': last_state, 'action_id': -1, 'to_state_id': -1, 'lon': last_lon, 'lat': last_lat}\n",
    "        final_df = pd.DataFrame(final_state, index=[0, ])\n",
    "        traj = pd.concat([traj, final_df], ignore_index=True)\n",
    "        \n",
    "        sequence_dfs = pd.concat([sequence_dfs, traj], ignore_index=True)\n",
    "    \n",
    "    ais_data = sequence_dfs\n",
    "        \n",
    "    print(sequence_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons ensuite plotly pour tracer les données sur une carte interactive, avec la possibilité de limiter le nombre de trajectoires que nous traçons dans l'intérêt de la performance et de l'esthétique. Les trajectoires peuvent être cliquées pour les agrandir afin de mieux discerner où va une trajectoire individuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'ais_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-5da0d6580f06>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mMAX_TRAJECTORIES\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mais_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mais_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mais_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'sequence_id'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mMAX_TRAJECTORIES\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mais_unique\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mais_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'lon'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'lat'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop_duplicates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# gets the unique coordinates we're going to plot\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ais_data' is not defined"
     ]
    }
   ],
   "source": [
    "# contrôle le nombre de trajectoires à tracer - mis à -1 pour tracer toutes les trajectoires disponibles\n",
    "MAX_TRAJECTORIES = 250\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "if MAX_TRAJECTORIES > -1:\n",
    "    ais_data = ais_data[ais_data['sequence_id'] < MAX_TRAJECTORIES]\n",
    "\n",
    "ais_unique = ais_data[['lon', 'lat']].drop_duplicates()  # obtient les coordonnées uniques que nous allons tracer\n",
    "    \n",
    "ais_states = [go.Scattergeo(\n",
    "    locationmode = 'USA-states',\n",
    "    lon = ais_unique['lon'],\n",
    "    lat = ais_unique['lat'],\n",
    "    hoverinfo = 'text',\n",
    "    text = ais_data['sequence_id'],\n",
    "    mode = 'markers',\n",
    "    marker = go.scattergeo.Marker(\n",
    "        size = 2,\n",
    "        color = 'red',\n",
    "        line = go.scattergeo.marker.Line(\n",
    "            width = 3,\n",
    "            color = 'rgba(68, 68, 68, 50)'\n",
    "        )\n",
    "    ))]\n",
    "\n",
    "\n",
    "ais_trajectories = []\n",
    "for traj_num, traj_data in ais_data.groupby('sequence_id'):\n",
    "    # obtient une couleur aléatoire pour chaque trajectoire\n",
    "    red = str(np.random.randint(0, high=230))\n",
    "    green = str(np.random.randint(0, high=230))\n",
    "    blue = str(np.random.randint(0, high=230))\n",
    "    ais_trajectories.append(\n",
    "        go.Scattergeo(\n",
    "            lon = traj_data['lon'],\n",
    "            lat = traj_data['lat'],\n",
    "            mode = 'lines',\n",
    "            line = go.scattergeo.Line(\n",
    "                width = 1,\n",
    "                color = 'rgb(' + red + ', ' + blue + ', ' + green + ')',\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=750,\n",
    "    title = go.layout.Title(\n",
    "        text = 'Shipping Data States Scatter'\n",
    "    ),\n",
    "    showlegend = False,\n",
    "    geo = go.layout.Geo(\n",
    "        scope = 'north america',\n",
    "        resolution = 50,\n",
    "        projection = go.layout.geo.Projection(\n",
    "            type = 'equirectangular'\n",
    "        ),\n",
    "        showland = True,\n",
    "        showlakes = True,\n",
    "        coastlinewidth = 2,\n",
    "        landcolor = 'rgb(204, 204, 204)',\n",
    "        lakecolor = 'rgb(255,255,255)',\n",
    "        countrycolor = 'rgb(190, 190, 190)',\n",
    "        lonaxis = go.layout.geo.Lonaxis(\n",
    "            range = [grid_params['min_lon'] - 25, grid_params['max_lon'] + 25],\n",
    "            showgrid = True,\n",
    "            dtick = grid_params['grid_len']\n",
    "        ),\n",
    "        lataxis = go.layout.geo.Lataxis(\n",
    "            range = [grid_params['min_lat'] - 15, grid_params['max_lat'] + 15],\n",
    "            showgrid = True,\n",
    "            dtick = grid_params['grid_len']\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = go.FigureWidget(data = ais_states + ais_trajectories, layout = layout)\n",
    "\n",
    "lines = fig.data[1:]\n",
    "\n",
    "# create our callback function\n",
    "def update_point(trace, points, selector):\n",
    "    if len(points.point_inds) > 0:\n",
    "        trace.line.width += 1\n",
    "\n",
    "for line in lines:\n",
    "    line.on_click(update_point)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}