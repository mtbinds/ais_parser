{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIS-PARSER DATA PLOTING\n",
    "\n",
    "In this demo, we'll be looking at a preprocessed csv file containing id-state-action-state transitions to plot the corresponding discretized ship trajectories on a map. For information on  how this csv was generated, please reference ``README.md`` or ``process_ais_data.py``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the metadata. The metadata specifies the dimensions and resolution of the grid in longitude and latitude (and more) so we can plot the discretized trajectories on a map by mapping coordinates to states. The ``grid_params['grid_len']`` is the side length of one square in degrees of a regular Euclidean grid with ``grid_params['num_cols']`` columns. With this information, we can deduce the boundaries of a grid square from an integer state. The metadata also contains a copy of how the preprocessing was performed so we can know the format of the csv. The csv will have 2 extra columns of longitude and latitude if ``options['append_coords']`` is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_files_meta': {'AIS_2020_01_02.csv': {'day': 2, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_03.csv': {'day': 3, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_04.csv': {'day': 4, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_05.csv': {'day': 5, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_06.csv': {'day': 6, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_07.csv': {'day': 7, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_08.csv': {'day': 8, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_09.csv': {'day': 9, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_10.csv': {'day': 10, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_11.csv': {'day': 11, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_12.csv': {'day': 12, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_13.csv': {'day': 13, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_14.csv': {'day': 14, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_15.csv': {'day': 15, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_16.csv': {'day': 16, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_17.csv': {'day': 17, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_18.csv': {'day': 18, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_19.csv': {'day': 19, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_20.csv': {'day': 20, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_21.csv': {'day': 21, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_22.csv': {'day': 22, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_23.csv': {'day': 23, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_24.csv': {'day': 24, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_25.csv': {'day': 25, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_26.csv': {'day': 26, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_27.csv': {'day': 27, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_28.csv': {'day': 28, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_29.csv': {'day': 29, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_30.csv': {'day': 30, 'month': 1, 'year': 2020},\n",
       "  'AIS_2020_01_31.csv': {'day': 31, 'month': 1, 'year': 2020}},\n",
       " 'directories': {'in_dir_data': 'ais_data_output.csv',\n",
       "  'in_dir_path': '../filtered_data_for_visualization/'},\n",
       " 'grid_params': {'grid_len': 0.5,\n",
       "  'max_lat': 50.0,\n",
       "  'max_lon': -61.0,\n",
       "  'min_lat': 25.0,\n",
       "  'min_lon': -141.0,\n",
       "  'num_cols': 160},\n",
       " 'options': {'allow_diag': False,\n",
       "  'append_coords': True,\n",
       "  'bound_lat': True,\n",
       "  'bound_lon': False,\n",
       "  'bound_time': True,\n",
       "  'interp_actions': True,\n",
       "  'limit_rows': True,\n",
       "  'max_rows': 100000,\n",
       "  'min_states': 2,\n",
       "  'prec_coords': 3}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_file= 'meta_data.yml'\n",
    "ais_meta = {}\n",
    "with open(meta_file, 'r') as stream:\n",
    "    try:\n",
    "        ais_meta = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "all_files_meta = ais_meta['all_files_meta']\n",
    "options = ais_meta['options']\n",
    "directories = ais_meta['directories']\n",
    "grid_params = ais_meta['grid_params']\n",
    "\n",
    "# specifies input directory and files of interest\n",
    "in_dir_path = directories['in_dir_path']\n",
    "in_dir_data = directories['in_dir_data']\n",
    "\n",
    "ais_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the sequences.\n",
    "\n",
    "In this dataset, there could be thousands of trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../filtered_data_for_visualization/ais_data_output.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-89b5b96b93e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reads in first file of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mais_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_dir_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mais_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \"\"\"\n\u001b[0;32m-> 1357\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../filtered_data_for_visualization/ais_data_output.csv'"
     ]
    }
   ],
   "source": [
    "# reads in first file of interest\n",
    "ais_data = pd.read_csv(in_dir_path + in_dir_data)\n",
    "\n",
    "ais_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that converts the ``state_id``s from the ``ais_data`` to the coordinates corresponding to the middle of that grid square for plotting if ``options['append_coords']`` was not set to ``True`` before preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_coord(state):\n",
    "    state_col = state % grid_params['num_cols']\n",
    "    state_row = state // grid_params['num_cols']\n",
    "    state_lon = grid_params['min_lon'] + grid_params['grid_len'] * (state_col + 0.5)\n",
    "    state_lat = grid_params['min_lat'] + grid_params['grid_len'] * (state_row + 0.5)\n",
    "    return state_lon, state_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use pandas to add coordinate columns to our dataframe that will contain the coordinates of the center of each state in each sequence, if this was not done in the preprocessing by setting ``options['append_coords']`` to ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not options['append_coords']:\n",
    "    ais_data[['lon', 'lat']] = ais_data.apply(lambda x: state_to_coord(x['from_state_id']), axis=1, result_type='expand')\n",
    "ais_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the latitudes and longitudes now available, we add a final row to each trajectory with just the last state so a one-to-one mapping of state to coordinates is formed, if this was not already done in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not options['append_coords']:\n",
    "    sequence_dfs = pd.DataFrame(columns=['sequence_id', 'from_state_id', 'action_id', 'to_state_id', 'lon', 'lat'])\n",
    "    for traj_num, traj in ais_data.groupby('sequence_id'):\n",
    "        # adds final dummy row to each sequence with just the final state in the trajectory\n",
    "        last_state = traj['to_state_id'].iloc[-1]\n",
    "        last_lon, last_lat = state_to_coord(last_state)\n",
    "\n",
    "        final_state = {'sequence_id': traj_num, 'from_state_id': last_state, 'action_id': -1, 'to_state_id': -1, 'lon': last_lon, 'lat': last_lat}\n",
    "        final_df = pd.DataFrame(final_state, index=[0, ])\n",
    "        traj = pd.concat([traj, final_df], ignore_index=True)\n",
    "        \n",
    "        sequence_dfs = pd.concat([sequence_dfs, traj], ignore_index=True)\n",
    "    \n",
    "    ais_data = sequence_dfs\n",
    "        \n",
    "    print(sequence_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use plotly to plot the data on an interactive map, with the option to limit the number of trajectories we plot in the interest of performance and aesthetics. Trajectories may be clicked to enlargen them to better discern where an individual trajectory goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'ais_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5da0d6580f06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mMAX_TRAJECTORIES\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mais_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mais_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mais_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMAX_TRAJECTORIES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mais_unique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mais_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# gets the unique coordinates we're going to plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ais_data' is not defined"
     ]
    }
   ],
   "source": [
    "# controls how many trajectories to plot - set to -1 to plot all trajectories available\n",
    "MAX_TRAJECTORIES = 250\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "if MAX_TRAJECTORIES > -1:\n",
    "    ais_data = ais_data[ais_data['sequence_id'] < MAX_TRAJECTORIES]\n",
    "\n",
    "ais_unique = ais_data[['lon', 'lat']].drop_duplicates()  # gets the unique coordinates we're going to plot\n",
    "    \n",
    "ais_states = [go.Scattergeo(\n",
    "    locationmode = 'USA-states',\n",
    "    lon = ais_unique['lon'],\n",
    "    lat = ais_unique['lat'],\n",
    "    hoverinfo = 'text',\n",
    "    text = ais_data['sequence_id'],\n",
    "    mode = 'markers',\n",
    "    marker = go.scattergeo.Marker(\n",
    "        size = 2,\n",
    "        color = 'red',\n",
    "        line = go.scattergeo.marker.Line(\n",
    "            width = 3,\n",
    "            color = 'rgba(68, 68, 68, 50)'\n",
    "        )\n",
    "    ))]\n",
    "\n",
    "\n",
    "ais_trajectories = []\n",
    "for traj_num, traj_data in ais_data.groupby('sequence_id'):\n",
    "    # gets random color for each trajectory\n",
    "    red = str(np.random.randint(0, high=230))\n",
    "    green = str(np.random.randint(0, high=230))\n",
    "    blue = str(np.random.randint(0, high=230))\n",
    "    ais_trajectories.append(\n",
    "        go.Scattergeo(\n",
    "            lon = traj_data['lon'],\n",
    "            lat = traj_data['lat'],\n",
    "            mode = 'lines',\n",
    "            line = go.scattergeo.Line(\n",
    "                width = 1,\n",
    "                color = 'rgb(' + red + ', ' + blue + ', ' + green + ')',\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=750,\n",
    "    title = go.layout.Title(\n",
    "        text = 'Shipping Data States Scatter'\n",
    "    ),\n",
    "    showlegend = False,\n",
    "    geo = go.layout.Geo(\n",
    "        scope = 'north america',\n",
    "        resolution = 50,\n",
    "        projection = go.layout.geo.Projection(\n",
    "            type = 'equirectangular'\n",
    "        ),\n",
    "        showland = True,\n",
    "        showlakes = True,\n",
    "        coastlinewidth = 2,\n",
    "        landcolor = 'rgb(204, 204, 204)',\n",
    "        lakecolor = 'rgb(255,255,255)',\n",
    "        countrycolor = 'rgb(190, 190, 190)',\n",
    "        lonaxis = go.layout.geo.Lonaxis(\n",
    "            range = [grid_params['min_lon'] - 25, grid_params['max_lon'] + 25],\n",
    "            showgrid = True,\n",
    "            dtick = grid_params['grid_len']\n",
    "        ),\n",
    "        lataxis = go.layout.geo.Lataxis(\n",
    "            range = [grid_params['min_lat'] - 15, grid_params['max_lat'] + 15],\n",
    "            showgrid = True,\n",
    "            dtick = grid_params['grid_len']\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = go.FigureWidget(data = ais_states + ais_trajectories, layout = layout)\n",
    "\n",
    "lines = fig.data[1:]\n",
    "\n",
    "# create our callback function\n",
    "def update_point(trace, points, selector):\n",
    "    if len(points.point_inds) > 0:\n",
    "        trace.line.width += 1\n",
    "\n",
    "for line in lines:\n",
    "    line.on_click(update_point)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
